{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.set_color_codes(\"pastel\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob ...  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher ...   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other ...   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other ...   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services ...   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other ...   \n",
       "\n",
       "  famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
       "0      4        3      4     1     1      3        6   5   6   6  \n",
       "1      5        3      3     1     1      3        4   5   5   6  \n",
       "2      4        3      2     2     3      3       10   7   8  10  \n",
       "3      3        2      2     1     1      5        2  15  14  15  \n",
       "4      4        3      2     1     2      5        4   6  10  10  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_datam = pd.read_csv(\"C:\\\\Users\\\\Suyash\\\\Downloads\\\\student-mat.csv\")\n",
    "student_datap = pd.read_csv(\"C:\\\\Users\\\\Suyash\\\\Downloads\\\\student-por.csv\")\n",
    "student_data = pd.concat([student_datam,student_datap])\n",
    "#Cleaning duplicates\n",
    "student_data=student_data.drop_duplicates([\"school\",\"sex\",\"age\",\"address\",\"famsize\",\"Pstatus\",\"Medu\",\"Fedu\",\"Mjob\",\"Fjob\",\"reason\",\"nursery\",\"internet\"])\n",
    "student_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "sns.distplot(student_data['Walc'],  \n",
    "             hist_kws={\"alpha\": 1, \"color\": \"#a2cffe\"}, \n",
    "             kde=False, bins=4)\n",
    "ax = ax.set(ylabel=\"Students\", xlabel=\"Weekend Alcohol Consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x11f7c5ecc18>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot1 = sns.factorplot(x=\"Walc\", y=\"health\", hue=\"sex\", data=student_data)\n",
    "plot1.set(ylabel=\"Health\", xlabel=\"Weekend Alcohol Consumption\")\n",
    "\n",
    "plot2 = sns.factorplot(x=\"Dalc\", y=\"health\", hue=\"sex\", data=student_data)\n",
    "plot2.set(ylabel=\"Health\", xlabel=\"Workday Alcohol Consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x11f7c647dd8>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot1 = sns.factorplot(x=\"G3\", y=\"Walc\", data=student_data)\n",
    "plot1.set(ylabel=\"Final Grade\", xlabel=\"Weekend Alcohol Consumption\")\n",
    "\n",
    "plot2 = sns.factorplot(x=\"G3\", y=\"Dalc\", data=student_data)\n",
    "plot2.set(ylabel=\"Final Grade\", xlabel=\"Workday Alcohol Consumption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496\n",
      "166\n"
     ]
    }
   ],
   "source": [
    "#First, decide how many training vs test samples you want\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "y = student_data['G3']\n",
    "X = student_data.drop(['G3'], axis=1)\n",
    "X = pd.get_dummies(X)\n",
    "num_all = student_data.shape[0]  # same as len(student_data)\n",
    "num_train = int(0.75*num_all)  # about 75% of the data\n",
    "num_test = num_all - num_train\n",
    "\n",
    "# TODO: Then, select features (X) and corresponding labels (y) for the training and test sets\n",
    "# Note: Shuffle the data or randomly select samples to avoid any bias due to ordering in the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  X, y, test_size=0.25, train_size = 0.75, random_state=0)\n",
    "\n",
    "print (X_train.shape[0])\n",
    "print (X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will look at cross-validation score from different machine learning models, The models I have taken are DecisionTreeRegressor , LinearRegression , Ridge and Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor: 0.597211835144\n",
      "LinearRegression: 0.797659207321\n",
      "Ridge: 0.798160300943\n",
      "Lasso: 0.824593486283\n"
     ]
    }
   ],
   "source": [
    "names = ['DecisionTreeRegressor', 'LinearRegression', 'Ridge', 'Lasso']\n",
    "\n",
    "clf_list = [DecisionTreeRegressor(),\n",
    "            LinearRegression(),\n",
    "            Ridge(),\n",
    "            Lasso()]\n",
    "for name, clf in zip(names, clf_list):\n",
    "    print(name, end=': ')\n",
    "    print(cross_val_score(clf, X, y, cv=5).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen The Ridge and Lasso model gave the best crossvalidation score. We will further analyze the data through F1 score and training time. The F1 Score is the 2*((precision*recall)/(precision+recall)). We have selected F1 score for analysis as it gives more accurate measure than precision and recall. A model can have very high precission but poor recall and vice-versa. So Analysis has to be done which takes into account both. Hence we select F1 score for analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor\n",
      "Done!\n",
      "Training time (secs):  0.025432586669921875\n"
     ]
    }
   ],
   "source": [
    "# Train a model\n",
    "import time\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    print (clf.__class__.__name__)\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    print (\"Done!\\nTraining time (secs): \",(end - start))\n",
    "\n",
    "# TODO: Choose a model, import it and instantiate an object\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeRegressor()\n",
    "\n",
    "# Fit model to training data\n",
    "train_classifier(clf, X_train, y_train)  # note: using entire training set here\n",
    "#print clf  # you can inspect the learned model by printing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels using {}... DecisionTreeRegressor\n",
      "Done!\n",
      "Prediction time (secs):  0.0\n",
      "F1 score for training set: {} 1.0\n",
      "Predicting labels using {}... DecisionTreeRegressor\n",
      "Done!\n",
      "Prediction time (secs):  0.0010001659393310547\n",
      "F1 score for test set: {} 0.37006497088\n"
     ]
    }
   ],
   "source": [
    "# Predict on training set and compute F1 score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def predict_labels(clf, features, target):\n",
    "    print (\"Predicting labels using {}...\",(clf.__class__.__name__))\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time.time()\n",
    "    print (\"Done!\\nPrediction time (secs): \",(end - start))\n",
    "    return f1_score(target.values, y_pred, pos_label='yes', average= 'weighted', labels=np.unique(y_pred))\n",
    "\n",
    "train_f1_score = predict_labels(clf, X_train, y_train)\n",
    "print (\"F1 score for training set: {}\",(train_f1_score))\n",
    "print (\"F1 score for test set: {}\",(predict_labels(clf, X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Training set size:  496\n",
      "DecisionTreeRegressor\n",
      "Done!\n",
      "Training time (secs):  0.01579904556274414\n",
      "Predicting labels using {}... DecisionTreeRegressor\n",
      "Done!\n",
      "Prediction time (secs):  0.004019498825073242\n",
      "F1 score for training set:  1.0\n",
      "Predicting labels using {}... DecisionTreeRegressor\n",
      "Done!\n",
      "Prediction time (secs):  0.0\n",
      "F1 score for test set:  0.348378626164\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train and predict from training set\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    print(\"------------------------------------------\")\n",
    "    print(\"Training set size: \",len(X_train))\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    print(\"F1 score for training set: \",predict_labels(clf, X_train, y_train))\n",
    "    print(\"F1 score for test set: \",predict_labels(clf, X_test, y_test))\n",
    "\n",
    "clf = tree.DecisionTreeRegressor()\n",
    "train_predict(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model which we took was Decision Tree Regressor. The model took very less training time but has not very good f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Training set size:  496\n",
      "SVC\n",
      "Done!\n",
      "Training time (secs):  0.13573741912841797\n",
      "Predicting labels using {}... SVC\n",
      "Done!\n",
      "Prediction time (secs):  0.06694173812866211\n",
      "F1 score for training set:  0.668797528787\n",
      "Predicting labels using {}... SVC\n",
      "Done!\n",
      "Prediction time (secs):  0.017154932022094727\n",
      "F1 score for test set:  0.426485711805\n"
     ]
    }
   ],
   "source": [
    "# Train and predict using SVC\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "train_predict(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Training set size:  496\n",
      "GaussianNB\n",
      "Done!\n",
      "Training time (secs):  0.010929107666015625\n",
      "Predicting labels using {}... GaussianNB\n",
      "Done!\n",
      "Prediction time (secs):  0.0078582763671875\n",
      "F1 score for training set:  0.211902025928\n",
      "Predicting labels using {}... GaussianNB\n",
      "Done!\n",
      "Prediction time (secs):  0.008934974670410156\n",
      "F1 score for test set:  0.0862638189454\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "train_predict(clf, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Training set size:  496\n",
      "RandomForestClassifier\n",
      "Done!\n",
      "Training time (secs):  0.06612944602966309\n",
      "Predicting labels using {}... RandomForestClassifier\n",
      "Done!\n",
      "Prediction time (secs):  0.009911060333251953\n",
      "F1 score for training set:  0.991889874793\n",
      "Predicting labels using {}... RandomForestClassifier\n",
      "Done!\n",
      "Prediction time (secs):  0.010133743286132812\n",
      "F1 score for test set:  0.307916284879\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "clf = ensemble.RandomForestClassifier()\n",
    "train_predict(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we used different model to train the dataset. The SVC model gave the best F1 score, although it took little longer than all other models. But still training time was not very large considering the amount of data we have at present. Therefore SVC model can be used to train the datasets. Next we use grid-search to optimize the parameters of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=200, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma=0.0001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Predicting labels using {}... SVC\n",
      "Done!\n",
      "Prediction time (secs):  0.056917428970336914\n",
      "F1 score for training set: {} 0.636237060432\n",
      "Predicting labels using {}... SVC\n",
      "Done!\n",
      "Prediction time (secs):  0.015566110610961914\n",
      "F1 score for test set: {} 0.340918454673\n"
     ]
    }
   ],
   "source": [
    "# TODO: Fine-tune your model and report the best F1 score\n",
    "from sklearn import grid_search\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "#cv = StratifiedShuffleSplit(y_train, random_state=42)\n",
    "cv=2\n",
    "clf = SVC()\n",
    "param_grid = [\n",
    "  {'C': [1, 10, 100, 200, 300, 400, 500, 600, 700],\n",
    "   'gamma': [1e-2, 1e-3, 1e-4, 1e-5, 1e-6],\n",
    "   'kernel': ['rbf'], 'tol':[1e-3, 1e-4, 1e-5, 1e-6]\n",
    "  }\n",
    " ]\n",
    "\n",
    "regressor = grid_search.GridSearchCV(clf, param_grid,cv=cv, scoring='f1_weighted')\n",
    "regressor.fit(X_train, y_train)\n",
    "reg = regressor.best_estimator_\n",
    "print (reg)\n",
    "train_f1_score = predict_labels(reg, X_train, y_train)\n",
    "print (\"F1 score for training set: {}\",train_f1_score)\n",
    "\n",
    "print (\"F1 score for test set: {}\",predict_labels(reg, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was optimized using grid search and final F1 score and training time were printed.\n",
    "----End of Analysis-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
